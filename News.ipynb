{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc5836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크롤링하고 싶은 뉴스 검색어를 입력해주세요: 데이터분석\n"
     ]
    }
   ],
   "source": [
    "#뉴스 데이터 스크랩\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sqlite3 \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "from html import escape\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def news_crawl(query=\"데이터분석\", start_page=1, end_page=10):\n",
    "    dbpath = \"news_info.db\" \n",
    "    conn = sqlite3.connect(dbpath)\n",
    "    cur = conn.cursor() \n",
    "\n",
    "    script = \"\"\"\n",
    "    DROP TABLE IF EXISTS news_crawl;\n",
    "\n",
    "    CREATE TABLE news_crawl(\n",
    "      id INTEGER PRIMARY KEY AUTOINCREMENT,  -- 뉴스의 ID 값\n",
    "      title TEXT,                            -- 뉴스의 제목\n",
    "      summary TEXT,                          -- 뉴스의 요약\n",
    "      link TEXT,                             -- 뉴스의 원문 링크\n",
    "      detailed_link TEXT,                    -- 뉴스의 상세 페이지 링크\n",
    "      content TEXT                           -- 뉴스의 본문 내용\n",
    "    );\n",
    "    \"\"\"\n",
    "    cur.executescript(script)\n",
    "\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "\n",
    "    for page in range(start_page, end_page + 1):\n",
    "        current_call = 1 + (page - 1) * 10\n",
    "        url = \"https://search.naver.com/search.naver?where=news&query=\" + query + \"&start=\" + str(current_call)\n",
    "\n",
    "        web = requests.get(url, headers=headers).content\n",
    "        source = BeautifulSoup(web, 'html.parser')\n",
    "\n",
    "        # 각 페이지 내의 모든 뉴스 기사를 순회합니다.\n",
    "        for article in source.find_all('div', {'class': 'news_area'}):\n",
    "            title = article.find('a', {'class': 'news_tit'}).get('title').replace(\"'\", \"''\")\n",
    "            link = article.find('a', {'class': 'news_tit'}).get('href').replace(\"'\", \"''\")\n",
    "            summary = article.find('a', {'class': 'api_txt_lines dsc_txt_wrap'}).get_text().replace(\"'\", \"''\")\n",
    "#             title = escape(title)\n",
    "#             summary = escape(summary)\n",
    "            detailed_url = \"\"\n",
    "            #네이버 뉴스에 등록된 뉴스만 사용\n",
    "            for urls in article.find_all('a', {'class': 'info'}):\n",
    "                if urls[\"href\"].startswith(\"https://n.news.naver.com\"):\n",
    "                    detailed_url = urls[\"href\"].replace(\"'\", \"''\")\n",
    "                    break\n",
    "            if detailed_url:\n",
    "                news_content = get_news_content(detailed_url).replace(\"'\", \"''\")\n",
    "                news_content = escape(news_content)\n",
    "                #뉴스본문 escape처리\n",
    "            else:\n",
    "                news_content = \"상세 페이지 링크 없음\"\n",
    "        \n",
    "            if news_content != \"상세 페이지 링크 없음\":\n",
    "                base_sql = \"INSERT INTO news_crawl(title, summary, link, detailed_link, content) values('{}','{}','{}','{}','{}')\"\n",
    "                sql_query = base_sql.format(title, summary, link, detailed_url, news_content)\n",
    "                cur.execute(sql_query)\n",
    "                conn.commit()\n",
    "            \n",
    "            \n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 사용자 입력을 통한 크롤링 실행\n",
    "query = input('크롤링하고 싶은 뉴스 검색어를 입력해주세요: ')\n",
    "news_crawl(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d636606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #데이터 확인용\n",
    "# import pandas as pd\n",
    "# import sqlite3\n",
    "\n",
    "# # 데이터베이스에서 데이터 읽기\n",
    "# conn = sqlite3.connect('news_info.db')\n",
    "# query = \"SELECT * FROM news_crawl\"\n",
    "# df = pd.read_sql_query(query, conn)\n",
    "# conn.close()\n",
    "\n",
    "# # 데이터를 HTML 파일로 변환\n",
    "# html_content = df.to_html()\n",
    "# with open(\"news_data.html\", \"w\", encoding='utf-8') as file:\n",
    "#     file.write(html_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dedc65e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [12/Jan/2024 12:45:34] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Jan/2024 12:45:34] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [12/Jan/2024 12:45:54] \"POST /process HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Jan/2024 12:46:25] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#final\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import sqlite3\n",
    "import html\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# API 키를 파일에서 읽기\n",
    "with open('OPENAI_API_KEY.txt', 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "def generate_gpt_content(news_content):\n",
    "    # Here you would call OpenAI's GPT model to generate content\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"'{news_content}' 위 내용을 바탕으로 한국어로 개선된 뉴스본문을 작성해. 그리고 50자 이내의 요약과 30자 이내의 제목도 생성해. 반드시 뉴스본문 앞에는 gpt_content: 를 요약 앞에는 gpt_summary: 를, 제목 앞에는 gpt_title: 을 붙여. 그리고 제목, 요약, 본문 순으로 나에게 보여줘.\"\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def show_news():\n",
    "    # 데이터베이스에서 뉴스 데이터를 가져옵니다.\n",
    "    conn = sqlite3.connect('news_info.db')\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM news_crawl\")\n",
    "    news_data = cur.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    decoded_news_data = []\n",
    "    for news in news_data:\n",
    "        decoded_content = news[5]#html.unescape(news[5])\n",
    "        decoded_news = list(news)\n",
    "        decoded_news[5] = decoded_content\n",
    "        decoded_news_data.append(decoded_news)\n",
    "        # HTML 템플릿에 데이터를 전달합니다.\n",
    "    return render_template('news_template.html', news_data=decoded_news_data)\n",
    "@app.route('/process', methods=['POST'])\n",
    "\n",
    "def process():\n",
    "    news_content = request.form['content']\n",
    "    decoded_content = html.unescape(news_content)\n",
    "    app.logger.info('Received content: %s', decoded_content)\n",
    "\n",
    "    gpt_response = generate_gpt_content(decoded_content)\n",
    "\n",
    "    return jsonify({'gpt_result': gpt_response})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795db86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
